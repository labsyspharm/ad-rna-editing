```{r setup, include=FALSE}
library(tidyverse)
library(synExtra)
library(here)
library(powerjoin)
library(qs)
library(ggbeeswarm)
library(Rsubread)

synapser::synLogin()
syn <- synExtra::synDownloader(normalizePath("~/data"), .cache = TRUE)
```


```{r}
raw_sprint <- synGlob(
  "syn64782901", "*.res"
) %>%
  enframe("raw_name", "syn_id") %>%
  mutate(
    file_path = map_chr(syn_id, syn),
    run_id = str_extract(raw_name, "SRR[0-9]+"),
    data = map(
      file_path,
      \(x) read_tsv(
        x,
        trim_ws = TRUE,
        skip = 1,
        col_names = c("chrom", "start", "end", "type", "supporting_reads", "strand", "ad_dp")
      ) %>%
        separate_wider_delim(
          ad_dp,
          delim = ":",
          names = c("ad", "dp")
        )
    )
  )

raw_sprint_long <- raw_sprint %>%
  select(run_id, data) %>%
  unnest(data) %>%
  select(-start) %>%
  rename(position = end)

write_csv(
  raw_sprint_long,
  "raw_sprint_long.csv.gz"
)
```

0-based exclusive to 1-based

```{r}
sprint_unique_sites <- raw_sprint_long %>%
  distinct(
    chrom,
    start = position,
    end = position
  )

# sprint_unique_granges <- sprint_unique_sites %>%
#   GenomicRanges::makeGRangesFromDataFrame()

# rtracklayer::export.bed(
#   sprint_unique_granges,
#   "sprint_unique.bed"
# )
```


```{r}
bam_files <- tibble(
  bam_path = Sys.glob(
    file.path("star_salmon", "*.sorted.bam")
  )
) %>%
  filter(!str_detect(bam_path, fixed("markdup"))) %>%
  mutate(
    sample_id = str_extract(bam_path, "([^/]+)\\.sorted\\.bam", group = 1)
  )
```


```{r}
sprint_saf <- sprint_unique_sites %>%
  transmute(
    GeneID = paste("Site", row_number(), sep = "_"),
    Chr = chrom,
    Start = start,
    End = end,
    Strand = "*"
  )

fc_results <- featureCounts(
  files = bam_files$bam_path,
  annot.ext = sprint_saf,
  isGTFAnnotationFile = FALSE,
  allowMultiOverlap = TRUE,
  isPairedEnd = TRUE,
  nthreads = 8
)

qsave(
  fc_results,
  "liu_unique_sprint_counts.qs"
)
# fc_results <- qread("liu_unique_sprint_counts.qs")

synStoreMany(
  c(
    "raw_sprint_long.csv.gz",
    "liu_unique_sprint_counts.qs"
  ),
  parentId = "syn64376902",
  forceVersion = FALSE
)

# sprint_counts_long <- fc_results$counts %>%
#   as_tibble() %>%
#   rename_with(
#     \(x) str_remove(x, fixed(".sorted.bam"))
#   )
```

```{r}
# library(processx)

# sprint_coverage_out_path <- tempfile()
# run(
#   "multiBamSummary",
#   c(
#     "BED-file",
#     "--BED", "sprint_unique.bed",
#     "--bamfiles", bam_files$bam_path,
#     "--labels", bam_files$sample_id,
#     "-p", 8,
#     "-v",
#     "--outRawCounts", sprint_coverage_out_path
#   ),
#   echo_cmd = TRUE,
#   stderr = "",
#   stdout = ""
# )
```


```{r}
# repeats_saf <- rm_raw %>%
#   transmute(
#     GeneID = paste(rep_name, row_number(), sep = "_"),
#     Chr = chromosome,
#     Start = start,
#     End = end,
#     Strand = case_when(
#       strand == "+" ~ "+",
#       strand == "C" ~ "-",
#       TRUE ~ "*"
#     )
#   )

# fc_results <- featureCounts(
#   files = bam_files$fastq_path,
#   annot.ext = repeats_saf,
#   isGTFAnnotationFile = FALSE,
#   allowMultiOverlap = TRUE,
#   isPairedEnd = TRUE,
#   nthreads = 8
# )

# qsave(
#   fc_results,
#   "liu_repeat_counts_raw.qs"
# )


# library(processx)

# pileup_out_path <- tempfile()
# run(
#   "samtools",
#   args = c(
#     "mpileup",
#     "-f", normalizePath("~/scratch/annotation/Homo_sapiens.GRCh38.dna.primary_assembly.fa"),
#     "-d", "0",
#     bam_files$bam_path
#   ),
#   echo_cmd = TRUE,
#   stderr = "",
#   stdout = pileup_out_path
# )

```
